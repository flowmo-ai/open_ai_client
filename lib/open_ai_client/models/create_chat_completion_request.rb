=begin
#OpenAI API

#The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

OpenAPI spec version: 2.3.0

Generated by: https://github.com/swagger-api/swagger-codegen.git
Swagger Codegen version: 3.0.66
=end

require 'date'

module OpenAIClient
  class CreateChatCompletionRequest
    # A list of messages comprising the conversation so far. Depending on the [model](/docs/models) you use, different message types (modalities) are supported, like [text](/docs/guides/text-generation), [images](/docs/guides/vision), and [audio](/docs/guides/audio). 
    attr_accessor :messages

    # ID of the model to use. See the [model endpoint compatibility](/docs/models#model-endpoint-compatibility) table for details on which models work with the Chat API.
    attr_accessor :model

    # Whether or not to store the output of this chat completion request for  use in our [model distillation](/docs/guides/distillation) or [evals](/docs/guides/evals) products. 
    attr_accessor :store

    # **o1 models only**   Constrains effort on reasoning for  [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response. 
    attr_accessor :reasoning_effort

    attr_accessor :metadata

    # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. 
    attr_accessor :frequency_penalty

    # Modify the likelihood of specified tokens appearing in the completion.  Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. 
    attr_accessor :logit_bias

    # Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`. 
    attr_accessor :logprobs

    # An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used. 
    attr_accessor :top_logprobs

    # The maximum number of [tokens](/tokenizer) that can be generated in the chat completion. This value can be used to control [costs](https://openai.com/api/pricing/) for text generated via API.  This value is now deprecated in favor of `max_completion_tokens`, and is not compatible with [o1 series models](/docs/guides/reasoning). 
    attr_accessor :max_tokens

    # An upper bound for the number of tokens that can be generated for a completion, including visible output tokens and [reasoning tokens](/docs/guides/reasoning). 
    attr_accessor :max_completion_tokens

    # How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs.
    attr_accessor :n

    attr_accessor :modalities

    # Configuration for a [Predicted Output](/docs/guides/predicted-outputs), which can greatly improve response times when large parts of the model response are known ahead of time. This is most common when you are regenerating a file with only minor changes to most of the content. 
    attr_accessor :prediction

    attr_accessor :audio

    # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics. 
    attr_accessor :presence_penalty

    # An object specifying the format that the model must output.  Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](/docs/guides/structured-outputs).  Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.  **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length. 
    attr_accessor :response_format

    # This feature is in Beta. If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result. Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend. 
    attr_accessor :seed

    # Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:   - If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.   - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.   - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarantee.   - When not set, the default behavior is 'auto'. 
    attr_accessor :service_tier

    # Up to 4 sequences where the API will stop generating further tokens. 
    attr_accessor :stop

    # If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions). 
    attr_accessor :stream

    attr_accessor :stream_options

    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both. 
    attr_accessor :temperature

    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.  We generally recommend altering this or `temperature` but not both. 
    attr_accessor :top_p

    # A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported. 
    attr_accessor :tools

    attr_accessor :tool_choice

    attr_accessor :parallel_tool_calls

    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). 
    attr_accessor :user

    # Deprecated in favor of `tool_choice`.  Controls which (if any) function is called by the model.  `none` means the model will not call a function and instead generates a message.  `auto` means the model can pick between generating a message or calling a function.  Specifying a particular function via `{\"name\": \"my_function\"}` forces the model to call that function.  `none` is the default when no functions are present. `auto` is the default if functions are present. 
    attr_accessor :function_call

    # Deprecated in favor of `tools`.  A list of functions the model may generate JSON inputs for. 
    attr_accessor :functions

    class EnumAttributeValidator
      attr_reader :datatype
      attr_reader :allowable_values

      def initialize(datatype, allowable_values)
        @allowable_values = allowable_values.map do |value|
          case datatype.to_s
          when /Integer/i
            value.to_i
          when /Float/i
            value.to_f
          else
            value
          end
        end
      end

      def valid?(value)
        !value || allowable_values.include?(value)
      end
    end

    # Attribute mapping from ruby-style variable name to JSON key.
    def self.attribute_map
      {
        :'messages' => :'messages',
        :'model' => :'model',
        :'store' => :'store',
        :'reasoning_effort' => :'reasoning_effort',
        :'metadata' => :'metadata',
        :'frequency_penalty' => :'frequency_penalty',
        :'logit_bias' => :'logit_bias',
        :'logprobs' => :'logprobs',
        :'top_logprobs' => :'top_logprobs',
        :'max_tokens' => :'max_tokens',
        :'max_completion_tokens' => :'max_completion_tokens',
        :'n' => :'n',
        :'modalities' => :'modalities',
        :'prediction' => :'prediction',
        :'audio' => :'audio',
        :'presence_penalty' => :'presence_penalty',
        :'response_format' => :'response_format',
        :'seed' => :'seed',
        :'service_tier' => :'service_tier',
        :'stop' => :'stop',
        :'stream' => :'stream',
        :'stream_options' => :'stream_options',
        :'temperature' => :'temperature',
        :'top_p' => :'top_p',
        :'tools' => :'tools',
        :'tool_choice' => :'tool_choice',
        :'parallel_tool_calls' => :'parallel_tool_calls',
        :'user' => :'user',
        :'function_call' => :'function_call',
        :'functions' => :'functions'
      }
    end

    # Attribute type mapping.
    def self.openapi_types
      {
        :'messages' => :'Object',
        :'model' => :'Object',
        :'store' => :'Object',
        :'reasoning_effort' => :'Object',
        :'metadata' => :'Object',
        :'frequency_penalty' => :'Object',
        :'logit_bias' => :'Object',
        :'logprobs' => :'Object',
        :'top_logprobs' => :'Object',
        :'max_tokens' => :'Object',
        :'max_completion_tokens' => :'Object',
        :'n' => :'Object',
        :'modalities' => :'Object',
        :'prediction' => :'Object',
        :'audio' => :'Object',
        :'presence_penalty' => :'Object',
        :'response_format' => :'Object',
        :'seed' => :'Object',
        :'service_tier' => :'Object',
        :'stop' => :'Object',
        :'stream' => :'Object',
        :'stream_options' => :'Object',
        :'temperature' => :'Object',
        :'top_p' => :'Object',
        :'tools' => :'Object',
        :'tool_choice' => :'Object',
        :'parallel_tool_calls' => :'Object',
        :'user' => :'Object',
        :'function_call' => :'Object',
        :'functions' => :'Object'
      }
    end

    # List of attributes with nullable: true
    def self.openapi_nullable
      Set.new([
        :'store',
        :'frequency_penalty',
        :'logit_bias',
        :'logprobs',
        :'top_logprobs',
        :'max_tokens',
        :'max_completion_tokens',
        :'n',
        :'prediction',
        :'presence_penalty',
        :'seed',
        :'service_tier',
        :'stream',
        :'temperature',
        :'top_p',
      ])
    end
  
    # Initializes the object
    # @param [Hash] attributes Model attributes in the form of hash
    def initialize(attributes = {})
      if (!attributes.is_a?(Hash))
        fail ArgumentError, "The input argument (attributes) must be a hash in `OpenAIClient::CreateChatCompletionRequest` initialize method"
      end

      # check to see if the attribute exists and convert string to symbol for hash key
      attributes = attributes.each_with_object({}) { |(k, v), h|
        if (!self.class.attribute_map.key?(k.to_sym))
          fail ArgumentError, "`#{k}` is not a valid attribute in `OpenAIClient::CreateChatCompletionRequest`. Please check the name to make sure it's valid. List of attributes: " + self.class.attribute_map.keys.inspect
        end
        h[k.to_sym] = v
      }

      if attributes.key?(:'messages')
        if (value = attributes[:'messages']).is_a?(Array)
          self.messages = value
        end
      end

      if attributes.key?(:'model')
        self.model = attributes[:'model']
      end

      if attributes.key?(:'store')
        self.store = attributes[:'store']
      else
        self.store = false
      end

      if attributes.key?(:'reasoning_effort')
        self.reasoning_effort = attributes[:'reasoning_effort']
      else
        self.reasoning_effort = 'medium'
      end

      if attributes.key?(:'metadata')
        self.metadata = attributes[:'metadata']
      end

      if attributes.key?(:'frequency_penalty')
        self.frequency_penalty = attributes[:'frequency_penalty']
      else
        self.frequency_penalty = 0
      end

      if attributes.key?(:'logit_bias')
        if (value = attributes[:'logit_bias']).is_a?(Hash)
          self.logit_bias = value
        end
      end

      if attributes.key?(:'logprobs')
        self.logprobs = attributes[:'logprobs']
      else
        self.logprobs = false
      end

      if attributes.key?(:'top_logprobs')
        self.top_logprobs = attributes[:'top_logprobs']
      end

      if attributes.key?(:'max_tokens')
        self.max_tokens = attributes[:'max_tokens']
      end

      if attributes.key?(:'max_completion_tokens')
        self.max_completion_tokens = attributes[:'max_completion_tokens']
      end

      if attributes.key?(:'n')
        self.n = attributes[:'n']
      else
        self.n = 1
      end

      if attributes.key?(:'modalities')
        self.modalities = attributes[:'modalities']
      end

      if attributes.key?(:'prediction')
        self.prediction = attributes[:'prediction']
      end

      if attributes.key?(:'audio')
        self.audio = attributes[:'audio']
      end

      if attributes.key?(:'presence_penalty')
        self.presence_penalty = attributes[:'presence_penalty']
      else
        self.presence_penalty = 0
      end

      if attributes.key?(:'response_format')
        self.response_format = attributes[:'response_format']
      end

      if attributes.key?(:'seed')
        self.seed = attributes[:'seed']
      end

      if attributes.key?(:'service_tier')
        self.service_tier = attributes[:'service_tier']
      else
        self.service_tier = 'auto'
      end

      if attributes.key?(:'stop')
        self.stop = attributes[:'stop']
      end

      if attributes.key?(:'stream')
        self.stream = attributes[:'stream']
      else
        self.stream = false
      end

      if attributes.key?(:'stream_options')
        self.stream_options = attributes[:'stream_options']
      end

      if attributes.key?(:'temperature')
        self.temperature = attributes[:'temperature']
      else
        self.temperature = 1
      end

      if attributes.key?(:'top_p')
        self.top_p = attributes[:'top_p']
      else
        self.top_p = 1
      end

      if attributes.key?(:'tools')
        if (value = attributes[:'tools']).is_a?(Array)
          self.tools = value
        end
      end

      if attributes.key?(:'tool_choice')
        self.tool_choice = attributes[:'tool_choice']
      end

      if attributes.key?(:'parallel_tool_calls')
        self.parallel_tool_calls = attributes[:'parallel_tool_calls']
      end

      if attributes.key?(:'user')
        self.user = attributes[:'user']
      end

      if attributes.key?(:'function_call')
        self.function_call = attributes[:'function_call']
      end

      if attributes.key?(:'functions')
        if (value = attributes[:'functions']).is_a?(Array)
          self.functions = value
        end
      end
    end

    # Show invalid properties with the reasons. Usually used together with valid?
    # @return Array for valid properties with the reasons
    def list_invalid_properties
      invalid_properties = Array.new
      if @messages.nil?
        invalid_properties.push('invalid value for "messages", messages cannot be nil.')
      end

      if @model.nil?
        invalid_properties.push('invalid value for "model", model cannot be nil.')
      end

      invalid_properties
    end

    # Check to see if the all the properties in the model are valid
    # @return true if the model is valid
    def valid?
      return false if @messages.nil?
      return false if @model.nil?
      reasoning_effort_validator = EnumAttributeValidator.new('Object', ['low', 'medium', 'high'])
      return false unless reasoning_effort_validator.valid?(@reasoning_effort)
      service_tier_validator = EnumAttributeValidator.new('Object', ['auto', 'default'])
      return false unless service_tier_validator.valid?(@service_tier)
      true
    end

    # Custom attribute writer method checking allowed values (enum).
    # @param [Object] reasoning_effort Object to be assigned
    def reasoning_effort=(reasoning_effort)
      validator = EnumAttributeValidator.new('Object', ['low', 'medium', 'high'])
      unless validator.valid?(reasoning_effort)
        fail ArgumentError, "invalid value for \"reasoning_effort\", must be one of #{validator.allowable_values}."
      end
      @reasoning_effort = reasoning_effort
    end

    # Custom attribute writer method checking allowed values (enum).
    # @param [Object] service_tier Object to be assigned
    def service_tier=(service_tier)
      validator = EnumAttributeValidator.new('Object', ['auto', 'default'])
      unless validator.valid?(service_tier)
        fail ArgumentError, "invalid value for \"service_tier\", must be one of #{validator.allowable_values}."
      end
      @service_tier = service_tier
    end

    # Checks equality by comparing each attribute.
    # @param [Object] Object to be compared
    def ==(o)
      return true if self.equal?(o)
      self.class == o.class &&
          messages == o.messages &&
          model == o.model &&
          store == o.store &&
          reasoning_effort == o.reasoning_effort &&
          metadata == o.metadata &&
          frequency_penalty == o.frequency_penalty &&
          logit_bias == o.logit_bias &&
          logprobs == o.logprobs &&
          top_logprobs == o.top_logprobs &&
          max_tokens == o.max_tokens &&
          max_completion_tokens == o.max_completion_tokens &&
          n == o.n &&
          modalities == o.modalities &&
          prediction == o.prediction &&
          audio == o.audio &&
          presence_penalty == o.presence_penalty &&
          response_format == o.response_format &&
          seed == o.seed &&
          service_tier == o.service_tier &&
          stop == o.stop &&
          stream == o.stream &&
          stream_options == o.stream_options &&
          temperature == o.temperature &&
          top_p == o.top_p &&
          tools == o.tools &&
          tool_choice == o.tool_choice &&
          parallel_tool_calls == o.parallel_tool_calls &&
          user == o.user &&
          function_call == o.function_call &&
          functions == o.functions
    end

    # @see the `==` method
    # @param [Object] Object to be compared
    def eql?(o)
      self == o
    end

    # Calculates hash code according to all attributes.
    # @return [Integer] Hash code
    def hash
      [messages, model, store, reasoning_effort, metadata, frequency_penalty, logit_bias, logprobs, top_logprobs, max_tokens, max_completion_tokens, n, modalities, prediction, audio, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, top_p, tools, tool_choice, parallel_tool_calls, user, function_call, functions].hash
    end

    # Builds the object from hash
    # @param [Hash] attributes Model attributes in the form of hash
    # @return [Object] Returns the model itself
    def self.build_from_hash(attributes)
      new.build_from_hash(attributes)
    end

    # Builds the object from hash
    # @param [Hash] attributes Model attributes in the form of hash
    # @return [Object] Returns the model itself
    def build_from_hash(attributes)
      return nil unless attributes.is_a?(Hash)
      self.class.openapi_types.each_pair do |key, type|
        if type =~ /\AArray<(.*)>/i
          # check to ensure the input is an array given that the attribute
          # is documented as an array but the input is not
          if attributes[self.class.attribute_map[key]].is_a?(Array)
            self.send("#{key}=", attributes[self.class.attribute_map[key]].map { |v| _deserialize($1, v) })
          end
        elsif !attributes[self.class.attribute_map[key]].nil?
          self.send("#{key}=", _deserialize(type, attributes[self.class.attribute_map[key]]))
        elsif attributes[self.class.attribute_map[key]].nil? && self.class.openapi_nullable.include?(key)
          self.send("#{key}=", nil)
        end
      end

      self
    end

    # Deserializes the data based on type
    # @param string type Data type
    # @param string value Value to be deserialized
    # @return [Object] Deserialized data
    def _deserialize(type, value)
      case type.to_sym
      when :DateTime
        DateTime.parse(value)
      when :Date
        Date.parse(value)
      when :String
        value.to_s
      when :Integer
        value.to_i
      when :Float
        value.to_f
      when :Boolean
        if value.to_s =~ /\A(true|t|yes|y|1)\z/i
          true
        else
          false
        end
      when :Object
        # generic object (usually a Hash), return directly
        value
      when /\AArray<(?<inner_type>.+)>\z/
        inner_type = Regexp.last_match[:inner_type]
        value.map { |v| _deserialize(inner_type, v) }
      when /\AHash<(?<k_type>.+?), (?<v_type>.+)>\z/
        k_type = Regexp.last_match[:k_type]
        v_type = Regexp.last_match[:v_type]
        {}.tap do |hash|
          value.each do |k, v|
            hash[_deserialize(k_type, k)] = _deserialize(v_type, v)
          end
        end
      else # model
        OpenAIClient.const_get(type).build_from_hash(value)
      end
    end

    # Returns the string representation of the object
    # @return [String] String presentation of the object
    def to_s
      to_hash.to_s
    end

    # to_body is an alias to to_hash (backward compatibility)
    # @return [Hash] Returns the object in the form of hash
    def to_body
      to_hash
    end

    # Returns the object in the form of hash
    # @return [Hash] Returns the object in the form of hash
    def to_hash
      hash = {}
      self.class.attribute_map.each_pair do |attr, param|
        value = self.send(attr)
        if value.nil?
          is_nullable = self.class.openapi_nullable.include?(attr)
          next if !is_nullable || (is_nullable && !instance_variable_defined?(:"@#{attr}"))
        end

        hash[param] = _to_hash(value)
      end
      hash
    end

    # Outputs non-array value in the form of hash
    # For object, use to_hash. Otherwise, just return the value
    # @param [Object] value Any valid value
    # @return [Hash] Returns the value in the form of hash
    def _to_hash(value)
      if value.is_a?(Array)
        value.compact.map { |v| _to_hash(v) }
      elsif value.is_a?(Hash)
        {}.tap do |hash|
          value.each { |k, v| hash[k] = _to_hash(v) }
        end
      elsif value.respond_to? :to_hash
        value.to_hash
      else
        value
      end
    end  end
end
